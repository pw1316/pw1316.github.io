---
layout: page
title: CS231N 解题报告
showbar: false
---

*本文不包含任何代码！*

# Assignment 1

## KNN

$$ distance_{ij}=\sqrt{\sum_{k}{(Test_{ik}-Train_{jk})^2}} $$

双循环对i和j分别循环，每次单独计算距离

单循环对i循环，$$ Test_{ik} $$广播到$$ Train $$的每一行

无循环，首先化简

$$
distance_{ij}=\sqrt{\sum_{k}{(Test_{ik}-Train_{jk})^2}}\\
=\sqrt{\sum_{k}{Test_{ik}^2}+\sum_{k}{Train_{jk}^2}-2\sum_{k}{Test_{ik}*Train_{jk}}}\\
distance=\sqrt{-2\langle Test,Train^T\rangle+sum(Test^2,-1)+sum(Train^2,-1)^T}
$$

点积部分不变，Test每行求和后作为行向量广播到距离矩阵每一行，Train每行求和后作为列向量广播到距离矩阵每一列

Cross-Validation分成5个Fold，5个batch，每个batch取4个Fold训练，剩下的一个验证，每个batch需要遍历所有k值，找到最佳的k

## SVM

数据预处理：使得训练数据0均值，其余数据集做相同加减

### 线性SVM

齐次空间将$$ WX+b $$化简为$$ WX $$

如果j不是第i个训练数据的正确标签：

$$ margin_{ij}=max(0,\langle X,W\rangle_{ij}-\langle X,W\rangle_{iy(i)}+1) $$

如果j是第i个训练数据的正确标签：

$$ margin_{ij}=0 $$

计算loss：

$$ loss=\frac{1}{n}\sum_i^n\sum_j^mmargin_{ij} $$

计算梯度：

$$ grad=\frac{1}{n}\sum_i^n\sum_j^m{\nabla margin_{ij}} $$

由于整体难以计算，考虑分项计算再求和。根据loss，所有为0的项对梯度贡献为0，因而只考虑大于0的项：

$$
\nabla margin_{ij}=\nabla \langle X,W\rangle_{ij}-\nabla \langle X,W\rangle_{iy(i)}\\
=(0_0,...,0_{j-1},{X_i}^T,0_{j+1},...,0_{m-1})-(0_0,...,0_{y_i-1},{X_{y_i}}^T,0_{y_i+1},...,0_{m-1})
$$

最后加上正则项的loss和梯度：

$$
L2loss=reg*{\Vert W \Vert}^2\\
L2grad=2*reg*W
$$

优化思路，矩阵整体用numpy计算会比循环快不少


